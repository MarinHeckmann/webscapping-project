{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeopyError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_city(city_name, country_name):\n",
    "    \"\"\"\n",
    "    Valide et récupère le nom standardisé d'une ville avec le pays en anglais via l'API Nominatim d'OpenStreetMap.\n",
    "    Permet d'envoyer à la fois le nom de la ville et du pays pour une recherche plus précise.\n",
    "    \n",
    "    Args:\n",
    "        city_name (str): Le nom de la ville à valider.\n",
    "        country_name (str): Le nom du pays dans lequel chercher la ville.\n",
    "        \n",
    "    Returns:\n",
    "        str: Le nom standardisé de la ville et du pays en anglais, ou None si la ville n'est pas trouvée.\n",
    "    \"\"\"\n",
    "    # Initialiser le géolocalisateur avec un user_agent\n",
    "    geolocator = Nominatim(user_agent=\"city_validation_test\")\n",
    "    \n",
    "    try:\n",
    "        # Formater la requête avec la ville et le pays\n",
    "        query = f\"{city_name}, {country_name}\"\n",
    "        \n",
    "        # Rechercher la ville dans le pays, en demandant les résultats en anglais\n",
    "        location = geolocator.geocode(query, addressdetails=True, exactly_one=True, language='en')\n",
    "        \n",
    "        if location:\n",
    "            # Extraction du nom de la ville et du pays en anglais\n",
    "            address_parts = location.address.split(\", \")\n",
    "            # On prend la première partie (ville) et la dernière (pays)\n",
    "            city_and_country = f\"{address_parts[0]}, {address_parts[-1]}\"\n",
    "            print(f\"City found: {city_and_country}\")\n",
    "            return city_and_country\n",
    "        else:\n",
    "            print(f\"City '{city_name}' in '{country_name}' not found.\")\n",
    "            return validate_city(input(\"Enter the city: \"),input(\"Enter the country: \"))\n",
    "    except GeopyError as e:\n",
    "        print(f\"Error querying city API: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_choice(prompt, options_dict):\n",
    "    \"\"\"\n",
    "    Demande à l'utilisateur de choisir une option parmi un dictionnaire de choix.\n",
    "    Si l'entrée est invalide, l'appelle récursivement pour redemander l'option.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Le message à afficher à l'utilisateur.\n",
    "        options_dict (dict): Dictionnaire contenant les options valides avec les clés comme choix.\n",
    "    \n",
    "    Returns:\n",
    "        str: La valeur correspondante à l'option choisie.\n",
    "    \"\"\"\n",
    "    # Affiche les options possibles\n",
    "    print(f\"Available options:\")\n",
    "    for key, value in options_dict.items():\n",
    "        print(f\"{key}. {value}\")\n",
    "    \n",
    "    try:\n",
    "        # Demander le choix à l'utilisateur\n",
    "        choice = int(input(prompt))\n",
    "        \n",
    "        # Vérifie que le choix est valide\n",
    "        if choice in options_dict:\n",
    "            return options_dict[choice]\n",
    "        else:\n",
    "            print(f\"Invalid choice. Choose from {', '.join(str(i) for i in options_dict.keys())}.\")\n",
    "            return get_choice(prompt, options_dict)  # Appel récursif si le choix est invalide\n",
    "    except ValueError:\n",
    "        print(f\"Please enter a valid number.\")\n",
    "        return get_choice(prompt, options_dict)  # Appel récursif si l'entrée n'est pas un nombre\n",
    "    \n",
    "    \n",
    "COSTS = {1: 'Affordable', 2: 'Mid-Range', 3: 'Premium', 4: 'Luxury'}\n",
    "SPORTIVITY_LEVELS = {1: 'Low', 2: 'Moderate', 3: 'High', 4: 'Extreme'}\n",
    "LANGUAGES = {1: 'English', 2: 'French', 3: 'German', 4: 'Spanish', 5: 'Italian', 6: 'Portuguese'}\n",
    "\n",
    "city = validate_city(input(\"Enter the city: \"),input(\"Enter the country: \"))\n",
    "language = get_choice(\"Enter the number corresponding to your language: \", LANGUAGES)\n",
    "\n",
    "# Demander le nombre d'activités\n",
    "num_activities = int(input(\"Enter the number of activities: \"))\n",
    "\n",
    "# Demander à l'utilisateur de choisir le niveau de sportivité\n",
    "sportivity = get_choice(f\"Enter the number corresponding to your sportivity level: ({', '.join(str(i) for i in SPORTIVITY_LEVELS.keys())}): \", SPORTIVITY_LEVELS)\n",
    "\n",
    "# Demander à l'utilisateur de choisir la catégorie de prix\n",
    "price_category = get_choice(f\"Enter the number corresponding to your price category: ({', '.join(str(i) for i in COSTS.keys())}): \", COSTS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(city_standard, language, num_activities, sportivity, price_category):\n",
    "\n",
    "    # Params communs\n",
    "    raw_params = {\"city\": city_standard}\n",
    "    processed_params = {\"city\": city_standard, \"language\": language}\n",
    "    cluster_params = {\"city\": city_standard, \"language\": language, \"sportivity\": sportivity, \"price_category\": price_category}\n",
    "    itinerary_params = {**cluster_params, \"num_activities\": num_activities}\n",
    "    a = \"df_\" + \"_\".join(str(value).replace(\",\",\"_\").replace(\" \", \"\").replace(\"'\", \"\").lower() for value in raw_params.values()) + \".csv\"\n",
    "    b = \"df_\" + \"_\".join(str(value).replace(\",\",\"_\").replace(\" \", \"\").replace(\"'\", \"\").lower() for value in processed_params.values()) + \".csv\"\n",
    "    c = \"df_\" + \"_\".join(str(value).replace(\",\",\"_\").replace(\" \", \"\").replace(\"'\", \"\").lower() for value in cluster_params.values()) + \".csv\"\n",
    "    d = \"df_\" + \"_\".join(str(value).replace(\",\",\"_\").replace(\" \", \"\").replace(\"'\", \"\").lower() for value in itinerary_params.values()) + \".csv\"\n",
    "\n",
    "\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    print(d)\n",
    "\n",
    "main(city, language, num_activities, sportivity, price_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test websites extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "import unicodedata\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "from difflib import get_close_matches\n",
    "\n",
    "\n",
    "def fetch_and_parse_page(url):\n",
    "    \"\"\"\n",
    "    Récupère et parse le contenu HTML d'une page web.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        # Récupérer la page\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Lève une exception pour les erreurs HTTP\n",
    "        \n",
    "        # Parser le contenu avec BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return soup\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la récupération de l'URL {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_html_to_txt(soup, filename,dir_path='C:/Users/glenn/OneDrive/Bureau/VScode saves/WebScrapping/Projet'):\n",
    "    \"\"\"\n",
    "    Sauvegarde le contenu HTML formaté dans un fichier texte.\n",
    "    \"\"\"\n",
    "    path=f'{dir_path}/{filename}.txt'\n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(soup.prettify())\n",
    "        print(f\"HTML sauvegardé dans le fichier : {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde du fichier : {e}\")\n",
    "\n",
    "\n",
    "def extract_text_by_class(soup, balise,class_name):\n",
    "    \"\"\"\n",
    "    Récupère tous les textes des balises <span> ayant une classe spécifique.\n",
    "    \"\"\"\n",
    "    # Chercher toutes les balises <span> avec la classe donnée\n",
    "    spans = soup.find_all(balise, class_=class_name)\n",
    "    \n",
    "    # Extraire et retourner le texte\n",
    "    return [span.get_text(strip=True) for span in spans]\n",
    "\n",
    "\n",
    "# Lonely planet extract\n",
    "def LonelyPlanet_attractions(soup):\n",
    "    \n",
    "    texts = extract_text_by_class(soup,\"span\", \"heading-05 font-semibold\")\n",
    "    df_LonelyPlanet=pd.DataFrame({'Title': texts})\n",
    "    df_LonelyPlanet.insert(0, 'site', 'LonelyPlanet')\n",
    "    df_LonelyPlanet['rank'] = range(len(df_LonelyPlanet))\n",
    "    return df_LonelyPlanet\n",
    "\n",
    "\n",
    "# Bucket List extract\n",
    "def BucketList_attractions(soup):\n",
    "\n",
    "    df_BucketList=pd.DataFrame()\n",
    "    # Trouver toutes les balises <article>\n",
    "    articles = soup.find_all('article', class_='listing-card bg-white shadow-listing')\n",
    "    # Initialiser une liste pour stocker les résultats\n",
    "\n",
    "    for article in articles:\n",
    "        # Extraire le titre de la balise <h2> (nom de l'attraction)\n",
    "        title_tag = article.find('h2', class_='text-2xl md:text-3xl font-bold')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else 'Titre non trouvé'\n",
    "\n",
    "        # Initialiser un dictionnaire pour stocker les informations de l'attraction\n",
    "        attraction_info = {'Title': title}\n",
    "\n",
    "        # Trouver toutes les balises <p> avec les informations sur la durée, l'âge, etc.\n",
    "        p_tags = article.find_all('p', class_='flex items-center space-x-1 text-lg')\n",
    "\n",
    "        for p in p_tags:\n",
    "            # Extraire le nom de la catégorie (par exemple \"Duration\", \"Good for age\", etc.)\n",
    "            label_tag = p.find_all('span')[1]\n",
    "            if label_tag:\n",
    "                label_value = label_tag.get_text(strip=True).split(':')\n",
    "                if len(label_value)==2:\n",
    "                    label=label_value[0]\n",
    "                    value=label_value[1]\n",
    "                    attraction_info[label] = value\n",
    "\n",
    "        # Ajouter l'attraction à la liste des résultats\n",
    "        df_BucketList = pd.concat([df_BucketList, pd.DataFrame([attraction_info])], ignore_index=True)\n",
    "    df_BucketList.insert(0, 'site', 'BucketList')\n",
    "    df_BucketList['rank'] = range(len(df_BucketList))\n",
    "    return df_BucketList\n",
    "\n",
    "\n",
    "# WorldTravelGuide extract\n",
    "def WorldTravelGuide_attractions(soup):\n",
    "\n",
    "    df_WorldTravelGuide=pd.DataFrame()\n",
    "    articles = soup.find_all('div', class_='high')\n",
    "    articles.extend(soup.find_all('div', class_='medium'))\n",
    "\n",
    "    for article in articles:\n",
    "        # Extraire le titre de la balise <h2> (nom de l'attraction)\n",
    "        title_tag = article.find('h3')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else 'Titre non trouvé'\n",
    "\n",
    "        # Initialisation du dictionnaire pour stocker les informations extraites\n",
    "        attraction_info = {'Title': title}\n",
    "\n",
    "        # Extraire la description\n",
    "        description_tag = article.find('p')\n",
    "        if description_tag:\n",
    "            attraction_info['Description'] = description_tag.get_text(strip=True)\n",
    "\n",
    "\n",
    "        # Extraire les horaires d'ouverture\n",
    "        opening_times_tag = article.find('b', string=\"Opening times: \")\n",
    "        if opening_times_tag:\n",
    "            opening_times = opening_times_tag.find_next('p')\n",
    "            if opening_times:\n",
    "                attraction_info['Opening times'] = opening_times.get_text(strip=True)\n",
    "\n",
    "        # Extraire le site Web\n",
    "        website_tag = article.find('b', string=\"Website: \")\n",
    "        if website_tag:\n",
    "            website = website_tag.find_next('a')\n",
    "            if website and website.get('href'):\n",
    "                attraction_info['Website'] = website.get('href')\n",
    "\n",
    "        # Extraire les frais d'admission\n",
    "        admission_fees_tag = article.find('b', string=\"Admission Fees: \")\n",
    "        if admission_fees_tag:\n",
    "            admission_fees = admission_fees_tag.find_next('p')\n",
    "            if admission_fees:\n",
    "                attraction_info['Admission Fees'] = admission_fees.get_text(strip=True)\n",
    "\n",
    "        # Extraire l'accès handicapé\n",
    "        disabled_access_tag = article.find('b', string=\"Disabled Access: \")\n",
    "        if disabled_access_tag:\n",
    "            #comment récupérer le texte juste après disabled_access_tag\n",
    "            disabled_access_text = disabled_access_tag.next_sibling.strip() if disabled_access_tag.next_sibling else 'Non spécifié'\n",
    "            attraction_info['Disabled Access'] = disabled_access_text\n",
    "        df_WorldTravelGuide = pd.concat([df_WorldTravelGuide, pd.DataFrame([attraction_info])], ignore_index=True)\n",
    "\n",
    "    df_WorldTravelGuide.insert(0, 'site', 'WorldTravelGuide')\n",
    "    df_WorldTravelGuide['rank'] = range(len(df_WorldTravelGuide))\n",
    "    return df_WorldTravelGuide\n",
    "\n",
    "\n",
    "def CNTraveler_attractions(soup):\n",
    "    df_CNTraveler=pd.DataFrame()\n",
    "    articles = soup.find_all('div', class_='GallerySlideFigCaption-dOeyTg gWbVWR')\n",
    "    for article in articles:\n",
    "        # Extraire le titre de l'attraction\n",
    "        title_tag = article.find('span',class_='GallerySlideCaptionHedText-iqjOmM jwPuvZ')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else 'Titre non trouvé'\n",
    "        attraction_info = {'Title': title}\n",
    "        description_tag = article.find('p')\n",
    "        if description_tag:\n",
    "            attraction_info['Description'] = description_tag.get_text(strip=True)\n",
    "        df_CNTraveler = pd.concat([df_CNTraveler, pd.DataFrame([attraction_info])], ignore_index=True)\n",
    "    df_CNTraveler.insert(0, 'site', 'CNTraveler')\n",
    "    df_CNTraveler['rank'] = range(len(df_CNTraveler))\n",
    "    return df_CNTraveler\n",
    "\n",
    "\n",
    "def Routard_attractions(soup):\n",
    "    df_Routard=pd.DataFrame()\n",
    "    articles = soup.find_all('div', class_='bg-rtd-grey-100 flex h-96 w-60 flex-col rounded-xl p-4')\n",
    "    for article in articles:\n",
    "        # Extraire le titre de l'attraction\n",
    "        title_tag = article.find('h2',class_='group-hover:text-rtd-green my-2 font-semibold')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else 'Titre non trouvé'\n",
    "        attraction_info = {'Title': title}\n",
    "        description_tag = article.find('div', class_='rtd-wysiwyg line-clamp-3')\n",
    "        if description_tag:\n",
    "            attraction_info['Description'] = description_tag.get_text(strip=True)\n",
    "        df_Routard = pd.concat([df_Routard, pd.DataFrame([attraction_info])], ignore_index=True)\n",
    "    df_Routard.insert(0, 'site', 'Routard')\n",
    "    df_Routard['rank'] = range(len(df_Routard))\n",
    "    return df_Routard\n",
    "\n",
    "\n",
    "def translate_location(name, src_lang=\"en\", dest_lang=\"fr\"):\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        translation = translator.translate(name, src=src_lang, dest=dest_lang).text\n",
    "        translation= translation.replace(\"'\",\"-\").replace(\" \",\"-\").lower()\n",
    "        #suppression des accents\n",
    "        translation = unicodedata.normalize('NFD', translation)\n",
    "        text = ''.join(char for char in translation if unicodedata.category(char) != 'Mn')\n",
    "    \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        return name\n",
    "\n",
    "def country_to_continent(country_name):\n",
    "    country_names = [country.name for country in pycountry.countries]\n",
    "    country = get_close_matches(country_name, country_names,n=1)\n",
    "    if len(country) == 1:\n",
    "        country_alpha2 = pc.country_name_to_country_alpha2(country[0])\n",
    "        country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "        country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "        return country_continent_name.lower()\n",
    "    else: return None\n",
    "\n",
    "def routard_city_to_region(city):\n",
    "    cities_to_regions = {\n",
    "        \"strasbourg\": \"alsace\",\n",
    "        \"bordeaux\": \"aquitaine-bordelais-landes\",\n",
    "        \"rennes\": \"bretagne\",\n",
    "        \"nice\": \"cote-d-azur\",\n",
    "        \"paris\": \"ile-de-france\",\n",
    "        \"montpellier\": \"languedoc-roussillon\",\n",
    "        \"toulouse\": \"midi-toulousain-occitanie\",\n",
    "        \"lille\": \"nord-pas-de-calais\",\n",
    "        \"nantes\": \"pays-de-la-loire\",\n",
    "        \"marseille\": \"provence\"\n",
    "    }\n",
    "    return cities_to_regions[city]\n",
    "\n",
    "def routard_continent(continent):\n",
    "    routard_continent_fr = {\n",
    "        \"europe\":\"europe\",\n",
    "        \"africa\":\"afrique\",\n",
    "        \"north america\":\"ameriques\",\n",
    "        \"south america\":\"ameriques\",\n",
    "        \"asia\":\"asie\",\n",
    "        \"oceania\":\"oceanie\"\n",
    "    }\n",
    "    return routard_continent_fr[continent]\n",
    "\n",
    "def main(country='france',city='paris',websites_to_call=['Routard','WorldTravelGuide','BucketList','LonelyPlanet','CNTraveler']):\n",
    "    continent = country_to_continent(country)\n",
    "    continent_fr = routard_continent(continent)\n",
    "    country_fr = translate_location(country)\n",
    "    city_fr = translate_location(city)\n",
    "\n",
    "    URL_dict={\n",
    "        'LonelyPlanet':f'https://www.lonelyplanet.com/{country}/{city}/attractions',\n",
    "        'BucketList':f'https://www.bucketlisttravels.com/destination/{city}/best-things-to-see-and-do',\n",
    "        'WorldTravelGuide':f'https://www.worldtravelguide.net/guides/{continent}/{country}/{city}/things-to-see/',\n",
    "        'CNTraveler':f'https://www.cntraveler.com/gallery/best-things-to-do-in-{city}',\n",
    "        'Routard':f'https://www.routard.com/fr/guide/top/{continent_fr}/{country_fr}/{city_fr}'\n",
    "    }\n",
    "    if country=='france':\n",
    "        region = routard_city_to_region (city_fr)\n",
    "\n",
    "        URL_dict['Routard']=f'https://www.routard.com/fr/guide/top/{country}/{region}/{city_fr}'\n",
    "\n",
    "    URL_extractor={\n",
    "        'LonelyPlanet_attractions': LonelyPlanet_attractions,\n",
    "        'BucketList_attractions':BucketList_attractions,\n",
    "        'WorldTravelGuide_attractions':WorldTravelGuide_attractions,\n",
    "        'CNTraveler_attractions':CNTraveler_attractions,\n",
    "        'Routard_attractions':Routard_attractions\n",
    "    }\n",
    "    df=pd.DataFrame()\n",
    "    for website in websites_to_call:\n",
    "        soup=fetch_and_parse_page(URL_dict[website])\n",
    "        #save_html_to_txt(soup,f'{website}_{city}')\n",
    "        if soup:\n",
    "            df=pd.concat([df,URL_extractor[f'{website}_attractions'](soup)],ignore_index=True)\n",
    "    return (df)\n",
    "        \n",
    "\n",
    "df_main=main(\"france\", \"nantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "name = \"la tour eiffel\"\n",
    "translation = translator.translate(name, src=\"fr\", dest=\"en\").text\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "def get_url_with_selenium(base_url, city_name):\n",
    "    \"\"\"\n",
    "    Utilise Selenium pour rechercher une ville et récupérer l'URL associée.\n",
    "    \n",
    "    :param base_url: Base URL du site Michelin (str).\n",
    "    :param city_name: Nom de la ville (str).\n",
    "    :return: URL complète ou message d'erreur.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configurer Selenium WebDriver avec des options (par exemple pour éviter les pop-ups)\n",
    "        #chrome_options = Options()\n",
    "        #chrome_options.add_argument(\"--start-maximized\")\n",
    "        driver = webdriver.Chrome( )\n",
    "        \n",
    "        # Accéder au site\n",
    "        driver.get(base_url)\n",
    "        time.sleep(2)  # Attendre le chargement de la page\n",
    "        \n",
    "        # Gérer la bannière de consentement si elle est présente\n",
    "        try:\n",
    "            consent_button = driver.find_element(By.ID, 'didomi-notice-agree-button')\n",
    "            consent_button.click()\n",
    "            print(\"button cliqué\")\n",
    "            time.sleep(4)  # Attendre après le clic\n",
    "        except Exception as e:\n",
    "            print(\"Bouton de consentement non trouvé ou déjà traité.\")\n",
    "        \n",
    "        # Trouver le champ de recherche et entrer la ville\n",
    "        search_box = driver.find_element(By.ID, \"autocomplete-1-input\")  # Adapter l'ID si nécessaire\n",
    "        #search_box = driver.find_element(By.XPATH,'//*[@id=\"autocomplete-1-input\"]')\n",
    "        print(search_box)\n",
    "        search_box.click()\n",
    "        time.sleep(2)\n",
    "        search_box.send_keys(city_name)\n",
    "        time.sleep(2)  # Attendre que l'autocomplétion s'affiche\n",
    "        \n",
    "        # Sélectionner la première suggestion\n",
    "        search_box.send_keys(Keys.ARROW_DOWN)\n",
    "        search_box.send_keys(Keys.ENTER)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Récupérer l'URL finale\n",
    "        final_url = driver.current_url\n",
    "        driver.quit()\n",
    "        return final_url\n",
    "    except Exception as e:\n",
    "        return f\"Erreur avec Selenium : {e}\"\n",
    "\n",
    "# Exemple d'utilisation\n",
    "base_url = \"https://guide.michelin.com/fr/fr\"\n",
    "city_name = \"Madrid\"\n",
    "print(get_url_with_selenium(base_url, city_name)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
